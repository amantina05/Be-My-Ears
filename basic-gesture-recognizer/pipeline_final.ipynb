{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, io, filters\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "from skimage.transform import resize\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility funtcion to compute area of overlap\n",
    "def overlapping_area(detection_1, detection_2):\n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[3]\n",
    "    x2_br = detection_2[0] + detection_2[3]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[4]\n",
    "    y2_br = detection_2[1] + detection_2[4]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br)-max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br)-max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[3] * detection_2[4]\n",
    "    area_2 = detection_2[3] * detection_2[4]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return overlap_area / float(total_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function randomly generates bounding boxes \n",
    "Return: hog vector of those cropped bounding boxes along with label \n",
    "Label : 1 if hand ,0 otherwise \n",
    "\"\"\"\n",
    "def buildhandnothand_lis(frame,imgset):\n",
    "    poslis =[]\n",
    "    neglis =[]\n",
    "    from collections import defaultdict\n",
    "    for nameimg in frame.image:\n",
    "        tupl = frame[frame['image']==nameimg].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        conf = 0\n",
    "        \n",
    "        dic = [0, 0]\n",
    "        \n",
    "        arg1 = [x_tl,y_tl,conf,side,side]\n",
    "        poslis.append(convertToGrayToHOG(crop(imgset[nameimg],x_tl,x_tl+side,y_tl,y_tl+side)))\n",
    "        while dic[0] <= 1 or dic[1] < 1:\n",
    "            x = random.randint(0,320-side)\n",
    "            y = random.randint(0,240-side) \n",
    "            crp = crop(imgset[nameimg],x,x+side,y,y+side)\n",
    "            hogv = convertToGrayToHOG(crp)\n",
    "            arg2 = [x,y, conf, side, side]\n",
    "            \n",
    "            z = overlapping_area(arg1,arg2)\n",
    "            if dic[0] <= 1 and z <= 0.5:\n",
    "                neglis.append(hogv)\n",
    "                dic[0] += 1\n",
    "            if dic[0]== 1:\n",
    "                break\n",
    "    label_1 = [1 for i in range(0,len(poslis)) ]\n",
    "    label_0 = [0 for i in range(0,len(neglis))]\n",
    "    label_1.extend(label_0)\n",
    "    poslis.extend(neglis)\n",
    "    return poslis,label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def getfiles(filenames):\n",
    "    dir_files = {}\n",
    "    for x in filenames:\n",
    "        dir_files[x]=io.imread(x)\n",
    "    return dir_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary(train_list):\n",
    "    frame = pd.DataFrame()\n",
    "    list_ = []\n",
    "    for user in train_list:\n",
    "        list_.append(pd.read_csv('./'+user+'/'+user+'_loc.csv',index_col=None,header=0))\n",
    "    frame = pd.concat(list_)\n",
    "    frame['side']=frame['bottom_right_x']-frame['top_left_x']\n",
    "    frame['hand']=1\n",
    "    #df = pd.DataFrame(buildhandnothand(frame,im),columns=['image','top_left_x','top_left_y','bottom_right_x','bottom_right_y','side','hand'])\n",
    "    #fin = pd.concat([df,frame])\n",
    "    imageset = getfiles(frame.image.unique())\n",
    "\n",
    "    return imageset,frame\n",
    "    #returns actual images and dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return hog of a particular image vector\n",
    "def convertToGrayToHOG(imgVector):\n",
    "    rgbImage = rgb2gray(imgVector)\n",
    "    return hog(rgbImage)\n",
    "#takes returns cropped image \n",
    "def crop(img,x1,x2,y1,y2):\n",
    "    crp=img[y1:y2,x1:x2]\n",
    "    crp=resize(crp,((128,128)))#resize\n",
    "    return crp\n",
    "def toCrop(d_bounds,files):\n",
    "    #format x1 y1 x2 y2\n",
    "    dir_cropped={}\n",
    "    for x in files: #x==file_name\n",
    "        y=files[x]\n",
    "        x=x.split('/')[-1]\n",
    "        dir_cropped[str(x)]=crop(y,int(d_bounds[x][0]),int(d_bounds[x][2]),int(d_bounds[x][1]),int(d_bounds[x][3]))\n",
    "    return dir_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dumpclassifier(filename,model):\n",
    "    \n",
    "    with open(filename, 'wb') as fid:\n",
    "        pickle.dump(model, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadClassifier(picklefile):\n",
    "    fd = open(picklefile, 'r+')\n",
    "    model = pickle.load(fd)\n",
    "    fd.close()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_binary_data(user_list):\n",
    "    data1,df  =train_binary(user_list)\n",
    "    #data 1 == actual images , df is sankets bounding box, third return is dataframe\n",
    "    z = buildhandnothand_lis(df,data1)\n",
    "    return data1,df,z[0],z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(user_list,img_dict):\n",
    "    #X = np.array([])\n",
    "    X = []\n",
    "    Y = []\n",
    "    for user in user_list:\n",
    "        user_images = glob.glob(user+'/*.jpg')\n",
    "#        img_dict = {}\n",
    "#         for img in user_images:\n",
    "#             img_dict[img] = io.imread(img)\n",
    "        boundingbox_df = pd.read_csv('./'+user+'/'+user+'_loc.csv')\n",
    "        \n",
    "        for rows in boundingbox_df.iterrows():\n",
    "            cropped_img = crop(img_dict[rows[1]['image']], rows[1]['top_left_x'], rows[1]['bottom_right_x'], rows[1]['top_left_y'], rows[1]['bottom_right_y'])\n",
    "            hogvector = convertToGrayToHOG(cropped_img)\n",
    "            X.append(hogvector.tolist())\n",
    "            Y.append(rows[1]['image'].split('/')[1][0])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def do_hardNegativeMining(cached_window,frame, imgset, model):   \n",
    "    lis = []\n",
    "    no_of_false_positives = 0\n",
    "    for nameimg in frame.image:\n",
    "        tupl = frame[frame['image']==nameimg].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        conf = 0\n",
    "        \n",
    "        dic = [0, 0]\n",
    "        \n",
    "        arg1 = [x_tl,y_tl,conf,side,side]\n",
    "        for x in range(0,320-side,32):\n",
    "            for y in range(0,240-side,24):\n",
    "                arg2 = [x,y,conf,side,side]\n",
    "                z = overlapping_area(arg1,arg2)\n",
    "                \n",
    "                \n",
    "                prediction = model.predict(cached_window[str(nameimg)+str(x)+str(y)])\n",
    "\n",
    "                if prediction == 1 and z<=0.5:\n",
    "                    lis.append(cached_window[str(nameimg)+str(x)+str(y)])\n",
    "                    no_of_false_positives += 1\n",
    "        \n",
    "#     falseneg = pd.DataFrame(lis)\n",
    "#     falseneg['label']=0\n",
    "    label = [0 for i in range(0,len(lis))]\n",
    "    return lis,label, no_of_false_positives\n",
    "    #return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def improve_Classifier_using_HNM(hog_list,label_list, frame, imgset, threshold): # frame - bounding boxes-df; yn_df - yes_or_no df\n",
    "    no_of_false_positives = 1000000\n",
    "    threshold = 50\n",
    "    i = 0\n",
    "    mnb  = MultinomialNB()\n",
    "    cached_wind = cacheSteps(imgset,frame,32,24)\n",
    "    while True:\n",
    "        i += 1\n",
    "        model = mnb.partial_fit(hog_list,label_list,classes = [0,1])\n",
    "\n",
    "        ret = do_hardNegativeMining(cached_wind,frame, imgset, model)\n",
    "        \n",
    "        hog_list = ret[0]\n",
    "        label_list = ret[1]\n",
    "        no_of_false_positives = ret[2]\n",
    "        \n",
    "        if no_of_false_positives == 0:\n",
    "            return model\n",
    "        \n",
    "        #yn_df.append(new_negatives_df)\n",
    "        #ho = new_negatives_df\n",
    "       \n",
    "        print \"Iteration {0} - No_of_false_positives: {1}\".format(i, no_of_false_positives)\n",
    "        #return ret\n",
    "\n",
    "        if no_of_false_positives <= threshold:\n",
    "            return model\n",
    "        \n",
    "        if i>10:\n",
    "             return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modifying to cache image values before hand so as to not redo that again and again \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def cacheSteps(imgset, frame ,step_x,step_y):\n",
    "    list_dic_of_hogs = []\n",
    "    dic = {}\n",
    "    for img in frame.image:\n",
    "        tupl = frame[frame['image']==img].values[0]\n",
    "        x_tl = tupl[1]\n",
    "        y_tl = tupl[2]\n",
    "        side = tupl[5]\n",
    "        \n",
    "        conf = 0\n",
    "\n",
    "        imaage = imgset[img]\n",
    "        for x in range(0,320-side,step_x):\n",
    "            for y in range(0,240-side,step_y):\n",
    "                dic[str(img+str(x)+str(y))]=convertToGrayToHOG(crop(imaage,x,x+side,y,y+side))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "from skimage import io\n",
    "\n",
    "# Returns the tuple with the highest prediction probability of hand\n",
    "def image_pyramid_step(model, img, scale=1.0):\n",
    "    max_confidence_seen = -1\n",
    "    rescaled_img = rescale(img, scale)\n",
    "    detected_box = []\n",
    "    side = 128\n",
    "    x_border = rescaled_img.shape[1]\n",
    "    y_border = rescaled_img.shape[0]\n",
    "    for x in range(0,x_border-side,8):\n",
    "        for y in range(0,y_border-side,6):\n",
    "            cropped_img = crop(rescaled_img,x,x+side,y,y+side)\n",
    "            hogvector = convertToGrayToHOG(cropped_img)\n",
    "\n",
    "            confidence = model.predict_proba(hogvector)\n",
    "            \n",
    "            if confidence[0][1] > max_confidence_seen:\n",
    "                detected_box = [x, y, confidence[0][1], scale]\n",
    "                max_confidence_seen = confidence[0][1]\n",
    "\n",
    "    return detected_box\n",
    " \n",
    "def build_image_pyramid(model, img, scales):\n",
    "    detectedBoxes = []\n",
    "    for scale in scales:\n",
    "        detectedBoxes.append(image_pyramid_step(model, img, scale))\n",
    "    return detectedBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## format [x,y,confidence,side ,side]\n",
    "# [x1,y1,x2,y2]\n",
    "# Malisiewicz et al.\n",
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # if the bounding boxes integers, convert them to floats --\n",
    "    # this is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    " \n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(s)\n",
    "\n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "        # the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_sree(handDetector, signDetector, imgvector,theirs):\n",
    "    scales = [1.25,\n",
    " 1.015625,\n",
    " 0.78125,\n",
    " 0.546875,\n",
    " 1.5625,\n",
    " 1.328125,\n",
    " 1.09375,\n",
    " 0.859375,\n",
    " 0.625,\n",
    " 1.40625,\n",
    " 1.171875,\n",
    " 0.9375,\n",
    " 0.703125,\n",
    " 1.71875,\n",
    " 1.484375]\n",
    "    detectedBoxes = [] ## [x,y,conf,scale]\n",
    "    for sc in scales:\n",
    "        detectedBoxes.append(image_pyramid_step(handDetector,imgvector,scale=sc))\n",
    "    \n",
    "    side = [0 for i in xrange(len(scales))]\n",
    "    for i in xrange(len(scales)):\n",
    "        side[i]= 128/scales[i]\n",
    "\n",
    "    for i in xrange(len(detectedBoxes)):\n",
    "        detectedBoxes[i][0]=detectedBoxes[i][0]/scales[i] #x\n",
    "        detectedBoxes[i][1]=detectedBoxes[i][1]/scales[i] #y\n",
    "#     ourBoundingBox = [detectedBoxes[maxidx][0], detectedBoxes[maxidx][1], side[maxidx]]\n",
    "    nms_lis = [] #[x1,x2,y1,y2]\n",
    "    for i in xrange(len(detectedBoxes)):\n",
    "        nms_lis.append([detectedBoxes[i][0],detectedBoxes[i][1],\n",
    "                        detectedBoxes[i][0]+side[i],detectedBoxes[i][1]+side[i],detectedBoxes[i][2]])\n",
    "    nms_lis = np.array(nms_lis)\n",
    "    \n",
    "    res = non_max_suppression_fast(nms_lis,0.4)\n",
    "    output_det = res[0]\n",
    "    x_top = output_det[0]\n",
    "    y_top = output_det[1]\n",
    "    side = output_det[2]-output_det[0]\n",
    "    our = [x_top,y_top,side]\n",
    "    \n",
    "    if isIoU_greater_than_half(our,theirs):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1 \n",
    "tot = 2 \n",
    "print \"accuracy: {0} in {1}\".format(count,tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for accuracy of localizer \n",
    "\n",
    "def get_sree_score(imageset,bb):\n",
    "    count = 0\n",
    "    tot = 0\n",
    "    for img in imageset:\n",
    "        tupl = bb[bb['image']==img].values[0]\n",
    "        count += get_prediction_sree(handDetector,signPredictor,imageset[img],[tupl[1],tupl[2],tupl[3]-tupl[1]])\n",
    "        tot+=1\n",
    "        print tot,count\n",
    "    print \"Accuracy : {0} in {1} \".format(count,tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_prediction(handDetector, signDetector, imgvector):\n",
    "#     scales = [1.25,\n",
    "#  1.015625,\n",
    "#  0.78125,\n",
    "#  0.546875,\n",
    "#  1.5625,\n",
    "#  1.328125,\n",
    "#  1.09375,\n",
    "#  0.859375,\n",
    "#  0.625,\n",
    "#  1.40625,\n",
    "#  1.171875,\n",
    "#  0.9375,\n",
    "#  0.703125,\n",
    "#  1.71875,\n",
    "#  1.484375]\n",
    "#     detectedBoxes = []\n",
    "# #     detectedBoxes.append(image_pyramid_step(handDetector, imgvector, scale=scales[0]))\n",
    "# #     detectedBoxes.append(image_pyramid_step(handDetector, imgvector, scale=scales[1]))\n",
    "# #     detectedBoxes.append(image_pyramid_step(handDetector, imgvector, scale=scales[2]))\n",
    "#     for sc in scales:\n",
    "#         detectedBoxes.append(image_pyramid_step(handDetector,imgvector,scale=sc))\n",
    "\n",
    "#     #format of detection box = [ x,y,conf,scale]\n",
    "#     side = [0 for i in xrange(len(scales))]\n",
    "#     for i in xrange(len(scales)):\n",
    "#         side[i]= 128/scales[i]\n",
    "\n",
    "#     for i in xrange(len(detectedBoxes)):\n",
    "#         detectedBoxes[i][0]=detectedBoxes[i][0]/scales[i] #x\n",
    "#         detectedBoxes[i][1]=detectedBoxes[i][1]/scales[i] #y\n",
    "# #format for nms -- [x-top-left, y-top-left, confidence-of-detections, width-of-detection, height-of-detection]\n",
    "# #     maxidx = detectedBoxes.index(max(detectedBoxes, key=lambda x:x[2]))\n",
    "# #     ourBoundingBox = [detectedBoxes[maxidx][0], detectedBoxes[maxidx][1], side[maxidx]]\n",
    "# #     nms_lis = []\n",
    "# #     for i in xrange(len(detectedBoxes)):\n",
    "# #         tmp = [detectedBoxes[i][0],detectedBoxes[i][1],detectedBoxes[i][2],side[i],side[i]]\n",
    "# #         nms_lis.append(tmp)\n",
    "    \n",
    "#     nms_lis = []\n",
    "#     for i in xrange(len(detectedBoxes)):\n",
    "#         nms_lis.append([detectedBoxes[i][0],detectedBoxes[i][1],\n",
    "#                         detectedBoxes[i][0]+side[i],detectedBoxes[i][1]+side[i]])\n",
    "    \n",
    "#     res = nms(nms_lis)\n",
    "# #     output_det= res[0]\n",
    "# #     x_top = output_det[0]\n",
    "# #     y_top = output_det[1]\n",
    "# #     side = output_det[3]\n",
    "#     output_det = res[0]\n",
    "#     x_top = output_det[0]\n",
    "#     y_top = output_det[1]\n",
    "#     side = output_det[2]-output_det[0]\n",
    "#     croppedImage = crop(imgvector, x_top, x_top+side, y_top, y_top+side )\n",
    "#     hogvec = convertToGrayToHOG(croppedImage)\n",
    "\n",
    "#     prediction = signDetector.predict_proba(hogvec)\n",
    "#     # probabilities = signDetector.predict_proba(hogvec)\n",
    "#     return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_mod(boxes,overlapThresh):\n",
    "    if len(boxes)==0:\n",
    "        return []\n",
    "    x1 = boxes[:,0]\n",
    "    x2 = boxes[:,1]\n",
    "    y1 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    s = boxes[:,4]\n",
    "    #s == score\n",
    "    area = (x2-x1+1) * ( y2-y1+1)\n",
    "    idxs = np.argsort(s)\n",
    "    \n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "\n",
    "    pick = []\n",
    "    \n",
    "    while len(idxs)>0:\n",
    "        last = len(idxs)-1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        \n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return only the bounding boxes that were picked using the\n",
    "    # integer data type\n",
    "    return boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that call the predictor fn\n",
    "def get_accuracy(handDetector, signDetector, imgvectors, labels):\n",
    "    c = 0\n",
    "    for i in xrange(len(imgvectors)):\n",
    "        print i \n",
    "        x = get_prediction(handDetector, signDetector, imgvectors[i])\n",
    "        zi = zip(signPredictor.classes_,x[0])\n",
    "        zi.sort(key = lambda x:x[1],reverse = True)\n",
    "        for j in xrange(5):\n",
    "            if labels[i] == zi[j][0]:\n",
    "                c += 1\n",
    "                break\n",
    "    return c,float(100*c)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(detection_boxes):\n",
    "    if len(detection_boxes)==0:\n",
    "        return []\n",
    "    #detection_boxes = sorted(detection_boxes,key = lambda detection_boxes:detection_boxes[2],reverse= True)\n",
    "    return max(detection_boxes,key =lambda detection_boxes:detection_boxes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimage():\n",
    "    image = io.imread('./user_4/B8.jpg')\n",
    "    for x in range(0,320-190,64):\n",
    "        for y in range(0,240-190,48):\n",
    "            cropped = crop(image,x,x+190,y,y+190)\n",
    "            io.imsave('x'+str(x)+'y'+str(y)+'.jpg',cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIoU_score(user_list):\n",
    "    # Read user_loc df\n",
    "    count = 0\n",
    "    total_count = 0\n",
    "    num_images_skipped = 0\n",
    "    \n",
    "    for user in user_list:\n",
    "        # For every img do the image pyramid\n",
    "        boundingBoxDf = pd.read_csv('./'+user+'/'+user+'_loc.csv',index_col=None,header=0)\n",
    "    \n",
    "        # images is a dict\n",
    "        images = getfiles(boundingBoxDf.image.unique())\n",
    "        \n",
    "        for imgname, imgvector in images.items():\n",
    "            total_count += 1\n",
    "        \n",
    "            scales = [1, 1.2, 0.7]\n",
    "            detectedBoxes = []\n",
    "            detectedBoxes.append(image_pyramid_step(model, imgvector, scale=scales[0]))\n",
    "            detectedBoxes.append(image_pyramid_step(model, imgvector, scale=scales[1]))\n",
    "            detectedBoxes.append(image_pyramid_step(model, imgvector, scale=scales[2]))\n",
    "            \n",
    "            \n",
    "            # side values\n",
    "            side = [0,0,0]\n",
    "            side[0] = 128/scales[0]\n",
    "            side[1] = 128/scales[1]\n",
    "            side[2] = 128/scales[2]\n",
    "                              \n",
    "            # x values\n",
    "            detectedBoxes[1][0] = detectedBoxes[1][0] / scales[1]\n",
    "            detectedBoxes[2][0] = detectedBoxes[2][0] / scales[2]\n",
    "                      \n",
    "            # y values\n",
    "            detectedBoxes[1][1] = detectedBoxes[1][1] / scales[1]\n",
    "            detectedBoxes[2][1] = detectedBoxes[2][1] / scales[2]\n",
    "            \n",
    "            maxidx = detectedBoxes.index(max(detectedBoxes, key=lambda x:x[2]))\n",
    "            ourBoundingBox = [detectedBoxes[maxidx][0], detectedBoxes[maxidx][1], side[maxidx]]\n",
    "                                 \n",
    "            givenBox = boundingBoxDf[boundingBoxDf['image']==imgname].values[0]\n",
    "            theirBoundingBox = [givenBox[1], givenBox[2], givenBox[3]-givenBox[1]]\n",
    "            \n",
    "            \n",
    "            if (isIoU_greater_than_half(ourBoundingBox, theirBoundingBox)):\n",
    "                count += 1\n",
    "                \n",
    "            else:\n",
    "                num_images_skipped += 1\n",
    "                print imgname, ourBoundingBox, detectedBoxes[maxidx][2]\n",
    "            \n",
    "                                 \n",
    "        print count\n",
    "        print total_count\n",
    "    print \"Final Score: {0}\\nNumber Of Images where IOU<0.5: {1}\\n\".format((count*100)/total_count, num_images_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isIoU_greater_than_half(detection_1, detection_2): # detection is a list - [x, y, side]; \n",
    "    x1_tl = detection_1[0]\n",
    "    x2_tl = detection_2[0]\n",
    "    x1_br = detection_1[0] + detection_1[2]\n",
    "    x2_br = detection_2[0] + detection_2[2]\n",
    "    y1_tl = detection_1[1]\n",
    "    y2_tl = detection_2[1]\n",
    "    y1_br = detection_1[1] + detection_1[2]\n",
    "    y2_br = detection_2[1] + detection_2[2]\n",
    "    # Calculate the overlapping Area\n",
    "    x_overlap = max(0, min(x1_br, x2_br)-max(x1_tl, x2_tl))\n",
    "    y_overlap = max(0, min(y1_br, y2_br)-max(y1_tl, y2_tl))\n",
    "    overlap_area = x_overlap * y_overlap\n",
    "    area_1 = detection_1[2] * detection_1[2]\n",
    "    area_2 = detection_2[2] * detection_2[2]\n",
    "    total_area = area_1 + area_2 - overlap_area\n",
    "    return (overlap_area / float(total_area)) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist=[ 'user_11', 'user_12','user_13','user_14','user_15','user_16','user_17','user_18','user_19','user_3',\n",
    "          'user_4','user_5','user_6','user_7','user_9','user_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr = userlist[:-4]\n",
    "user_te = userlist[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# loading part2 ka stuff\n",
    "imageset,boundbox,hog_list,label_list = load_binary_data(user_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_mul,Y_mul = get_data(user_tr,imageset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = loadClassifier('label_en (1).pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mul = le.transform(Y_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageset_test, bound_box_test = train_binary(user_te)\n",
    "images = []\n",
    "imagename =  []\n",
    "labels = []\n",
    "for img in imageset_test:\n",
    "    images.append(imageset_test[img])\n",
    "    label = img.split('/')[1][0]\n",
    "    labels.append(label)\n",
    "    imagename.append(img)\n",
    "labels1 = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LinearSVC(),hog_list,label_list,cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(MultinomialNB(),hog_list,label_list,cv = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(hog_list,label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# model = improve_Classifier_using_HNM(hogdf,boundbox,imageset,50)\n",
    "# #imageset,boundbox,hogdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model = improve_Classifier_using_HNM(hog_list,label_list,boundbox,imageset,50)\n",
    "#imageset,boundbox,hogdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpclassifier('binary_classifier_smallsteps_15_nov.pkl',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign these the appr. models\n",
    "signPredictor = loadClassifier('linear_svc_part_1.pkl')\n",
    "handDetector = loadClassifier('bin_class_12_users.pkl')\n",
    "\n",
    "# We'll need:\n",
    "# imgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = nms_lis[:,0]\n",
    "y1 = nms_lis[:,1]\n",
    "x2 = nms_lis[:,2]\n",
    "y2 = nms_lis[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the area of the bounding boxes and sort the bounding\n",
    "# boxes by the bottom-right y-coordinate of the bounding box\n",
    "area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "idxs = np.argsort(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = io.imread('user_10/A4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [1.25,\n",
    "1.015625,\n",
    "0.78125,\n",
    "0.546875,\n",
    "1.5625,\n",
    "1.328125,\n",
    "1.09375,\n",
    "0.859375,\n",
    "0.625,\n",
    "1.40625,\n",
    "1.171875,\n",
    "0.9375,\n",
    "0.703125,\n",
    "1.71875,\n",
    "1.484375]\n",
    "detectedBoxes = []\n",
    "scalesfoll = []\n",
    "for sc in scales:\n",
    "    scalesfoll.append(sc)\n",
    "    detectedBoxes.append(image_pyramid_step(handDetector,z,scale=sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectedBoxes1 = detectedBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectedBoxes1 #[x1,y1,conf,scale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(rescale(z,0.546875))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = rescale(z,0.546875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "96+128\n",
    "io.imshow(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(rr[0:0+128][32:32+128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = [0 for i in xrange(len(detectedBoxes))]\n",
    "for i in xrange(len(detectedBoxes)):\n",
    "    side[i]= 128/scales[i]\n",
    "\n",
    "for i in xrange(len(detectedBoxes)):\n",
    "    detectedBoxes[i][0]=detectedBoxes[i][0]/scales[i] #x\n",
    "    detectedBoxes[i][1]=detectedBoxes[i][1]/scales[i] #y\n",
    "#     ourBoundingBox = [detectedBoxes[maxidx][0], detectedBoxes[maxidx][1], side[maxidx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nms_lis = []\n",
    "for i in xrange(len(detectedBoxes)):\n",
    "    nms_lis.append([detectedBoxes[i][0],detectedBoxes[i][1],\n",
    "                    detectedBoxes[i][0]+side[i],detectedBoxes[i][1]+side[i],detectedBoxes[i][2]])\n",
    "#[x1,y1,x2,y2]\n",
    "nms_lis = np.array(nms_lis)\n",
    "res = non_max_suppression_fast(nms_lis,0.3)\n",
    "output_det = res[0]\n",
    "x_top = output_det[0]\n",
    "y_top = output_det[1]\n",
    "side1 = output_det[2]-output_det[0]\n",
    "our = [x_top,y_top,side1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}